{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b694d5b3-2053-4cb1-8bf9-fe83dfa024d7",
   "metadata": {},
   "source": [
    "# Описание задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0cb1ad-299c-4b1c-84ae-233efdcd46b2",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \\\n",
    "\\\n",
    "Обучить модель - классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "Необходимо построить модель со значением метрики качества F1 не меньше 0.75."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe921d7c",
   "metadata": {},
   "source": [
    "# Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc677a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: colab 1.13.5 has a non-standard dependency specifier pytz>=2011n. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of colab or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -q pymystem3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74223deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: colab 1.13.5 has a non-standard dependency specifier pytz>=2011n. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of colab or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -q tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d5d004b-8902-4735-bf9a-bbb200a730a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: colab 1.13.5 has a non-standard dependency specifier pytz>=2011n. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of colab or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -q imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9985154",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexander/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import re\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer  \n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66d8c720-22ba-404f-84f5-9164d508505f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#constants\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61fe3f27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  toxic\n",
       "0           0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1           1  D'aww! He matches this background colour I'm s...      0\n",
       "2           2  Hey man, I'm really not trying to edit war. It...      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    df = pd.read_csv('toxic_comments.csv')\n",
    "except:\n",
    "    df = pd.read_csv('/datasets/toxic_comments.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41b25503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  159292 non-null  int64 \n",
      " 1   text        159292 non-null  object\n",
      " 2   toxic       159292 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b99e86f",
   "metadata": {},
   "source": [
    "# Предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2082317f",
   "metadata": {},
   "source": [
    "Удалим ненужный столбец"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "013a9b41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns='Unnamed: 0')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2edcd563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b8abf64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fc0170",
   "metadata": {},
   "source": [
    "Дубликатов нет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df130acc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['toxic'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "918fcbc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля с классом_0 = 0.898\n",
      "Доля с классом_1 = 0.102\n"
     ]
    }
   ],
   "source": [
    "toxic_0 = df[df['toxic'] == 0]['toxic'].count()\n",
    "toxic_1 = df[df['toxic'] == 1]['toxic'].count()\n",
    "print('Доля с классом_0 = {}'.format(round(toxic_0 / df['toxic'].count(), 3)))\n",
    "print('Доля с классом_1 = {}'.format(round(toxic_1 / df['toxic'].count(), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef4b3faf-53c6-4d81-927d-a73db426bb56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159292, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4429b033-cd93-46d6-af06-f5f04765eea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10aa902f-e5ff-4da6-aab9-80b40f4fbb84",
   "metadata": {},
   "source": [
    "Обнаружен дисбаланс классов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e815b8e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff861d4-534b-4e57-80fb-5d9cfba75ca9",
   "metadata": {},
   "source": [
    "Создадим фунцию, которая подготавливает текст к обучению: \n",
    "- лемматизация \n",
    "- удаление стоп-слов\n",
    "- удаление специальных знаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48a360fc-aa8d-4bcf-8fa8-05b92e6c593f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "\n",
    "def clean_text(text):\n",
    "    \n",
    "    text = text.lower()\n",
    "    \n",
    "    text = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", text)\n",
    "\n",
    "    text = re.sub(r\"http\\S+\", \"\",text)\n",
    "    \n",
    "    html=re.compile(r'<.*?>') \n",
    "    \n",
    "    text = html.sub(r'',text)\n",
    "    \n",
    "    punctuations = '@#!?+&*[]-%.:/();$=><|{}^' + \"'`\" + '_'\n",
    "    for p in punctuations:\n",
    "        text = text.replace(p,'')\n",
    "        \n",
    "    text = [word.lower() for word in text.split() if word.lower() not in sw]\n",
    "    \n",
    "    text = [lemmatizer.lemmatize(word) for word in text]\n",
    "    \n",
    "    text = \" \".join(text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6150ac82-134e-433f-ac98-46754e65b90f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>explanation edits made username hardcore metal...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aww match background colour seemingly stuck th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey man, really trying edit war guy constantly...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>make real suggestion improvement wondered sect...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you, sir, hero chance remember page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  explanation edits made username hardcore metal...      0\n",
       "1  aww match background colour seemingly stuck th...      0\n",
       "2  hey man, really trying edit war guy constantly...      0\n",
       "3  make real suggestion improvement wondered sect...      0\n",
       "4                you, sir, hero chance remember page      0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'] = df['text'].apply(lambda x: clean_text(x))\n",
    " \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b489d2-62b8-4758-8454-60f646ee3312",
   "metadata": {},
   "source": [
    "Разделим датасет на обучающую, валидационную и тестовую выборки, а также сделаем векторизацию корпуса из текстов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "464413d7-f591-4869-b7ff-4b68b198bf9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(114689,)\n",
      "(28673,)\n",
      "(15930,)\n",
      "(114689,)\n",
      "(28673,)\n",
      "(15930,)\n"
     ]
    }
   ],
   "source": [
    "X_train_valid, X_test , y_train_valid, y_test = train_test_split(\n",
    "    df['text'].values,\n",
    "    df['toxic'].values,\n",
    "    test_size=0.1,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=df['toxic'].values)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_valid,\n",
    "    y_train_valid,\n",
    "    test_size=0.2,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y_train_valid)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_valid.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b0182e2-9081-4411-9386-e9857e7dfc07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(114689, 143746)\n",
      "(28673, 143746)\n",
      "(15930, 143746)\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer() \n",
    "features_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "features_valid = tfidf_vectorizer.transform(X_valid)\n",
    "features_test = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "print(features_train.shape)\n",
    "print(features_valid.shape)\n",
    "print(features_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083596e5-3d8d-4766-bf73-9ed1b245c812",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Обучение моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9a97c7-fe8b-46f0-bbe0-3003fb30ab61",
   "metadata": {},
   "source": [
    "Так как на этапе предобработки данных мы обнаружили дисбаланс классов, необходимо учесть этот факт в ходе обучения моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b6b63b0-5f89-44e5-9406-e9a8d9671ffd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5565536 , 4.92058521])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372eebec-3b5d-4754-884c-9cc53092ba09",
   "metadata": {},
   "source": [
    "Словарь весов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa792926-52f9-477b-b5f8-a3ca14e3b35f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.556555078310615, 1: 4.920469522240527}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dft = {\n",
    "    0: 0.556555078310615, \n",
    "    1: 4.920469522240527\n",
    "}\n",
    "dft"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfab59b9-e2de-4d14-aa1c-14390384bf34",
   "metadata": {
    "tags": []
   },
   "source": [
    "## DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2959befa-df7b-4c24-8677-93d3ddfcf1cb",
   "metadata": {},
   "source": [
    "Так как подбор всех гиперпараметров решающего дерева занимает длительное время, то разделим этот процесс на два этапа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "15853fff-bd20-4fe7-80cf-1dd7dd5388ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score = 0.6645109705130744\n",
      "Best params:\n",
      "{'criterion': 'entropy', 'splitter': 'random'}\n"
     ]
    }
   ],
   "source": [
    "model_tree = DecisionTreeClassifier(random_state=RANDOM_STATE, class_weight=dft)\n",
    "PARAMS_TREE = {\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'], \n",
    "    'splitter': ['best', 'random']\n",
    "}\n",
    "\n",
    "grid_tree = GridSearchCV(model_tree, PARAMS_TREE, cv=5, scoring='f1')\n",
    "grid_tree.fit(features_train, y_train)\n",
    "\n",
    "print('Best score = {}'.format(grid_tree.best_score_))\n",
    "print('Best params:')\n",
    "print(grid_tree.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ae5aef-6ea0-468e-90c8-d75533b26e2f",
   "metadata": {
    "tags": []
   },
   "source": [
    "Теперь подберем глубину решающего дерева"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d9beeba9-2048-40aa-b761-1c57426d5866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best depth = 600\n",
      "Best best_f1 = 0.6937605396290051\n"
     ]
    }
   ],
   "source": [
    "best_model = None\n",
    "best_depth = None\n",
    "best_f1 = 0\n",
    "for depth in range(50, 601, 50):\n",
    "    model_tree = DecisionTreeClassifier(random_state=RANDOM_STATE, \n",
    "                                    criterion='entropy', \n",
    "                                    splitter='random',\n",
    "                                    max_depth=depth,\n",
    "                                    class_weight=dft)\n",
    "\n",
    "    model_tree.fit(features_train, y_train)\n",
    "    predict_valid = model_tree.predict(features_valid)\n",
    "    f1 = f1_score(y_valid, predict_valid)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_model = model_tree\n",
    "        best_depth = depth\n",
    "\n",
    "print('Best depth = {}'.format(best_depth))\n",
    "print('Best best_f1 = {}'.format(best_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a966b059-bdf5-492e-b6e8-437d60cacb3c",
   "metadata": {},
   "source": [
    "### Valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9f4b1630-a1ab-4a3b-8789-80f9df0255b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6937605396290051"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tree = DecisionTreeClassifier(random_state=RANDOM_STATE, \n",
    "                                    criterion='entropy', \n",
    "                                    splitter='random',\n",
    "                                    max_depth=350,\n",
    "                                    class_weight=dft)\n",
    "model_tree.fit(features_train, y_train)\n",
    "predict_valid = best_model.predict(features_valid)\n",
    "\n",
    "f1_score(y_valid, predict_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ec1c41-7fbe-42b6-b2f4-596fd3f51bcb",
   "metadata": {},
   "source": [
    "**Вывод:** Качество модели хуже, чем предыдущая рассмотренная модель F1 = 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ebb843-06c4-4dc6-a2bb-7feb50dab084",
   "metadata": {
    "tags": []
   },
   "source": [
    "## RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6371cfd-5544-49da-8f89-42dc876db18b",
   "metadata": {},
   "source": [
    "Используем кросс-валидацию для подбора гиперпараметров"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4745b83-c317-4692-9aad-b9d8e701b8b1",
   "metadata": {},
   "source": [
    "### Cross valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2cf039ad-7fb1-452a-9c85-cfc55dd506c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'n_estimators': 50, 'max_depth': 18}\n"
     ]
    }
   ],
   "source": [
    "param_dist = {'n_estimators': range(50, 500, 50),\n",
    "              'max_depth': range(1, 20)}\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "rand_search = RandomizedSearchCV(rf, \n",
    "                                 param_distributions = param_dist, \n",
    "                                 n_iter=5, \n",
    "                                 cv=5)\n",
    "\n",
    "rand_search.fit(features_train, y_train)\n",
    "\n",
    "best_rf = rand_search.best_estimator_\n",
    "\n",
    "print('Best hyperparameters:',  rand_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b12d48-1da5-48cb-b77f-ebbbe8bb2d74",
   "metadata": {},
   "source": [
    "### Valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "47c61ce9-4776-4a6d-9130-3cf6bd886a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best best_f1 = 0.0006863417982155114\n"
     ]
    }
   ],
   "source": [
    "best_rf.fit(features_train, y_train)\n",
    "predict_valid = best_rf.predict(features_valid)\n",
    "f1 = f1_score(y_valid, predict_valid)\n",
    "\n",
    "print('Best best_f1 = {}'.format(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd6a771-56b3-460d-a228-c33a7b009dad",
   "metadata": {},
   "source": [
    "**Вывод:** Модель **RandomForestClassifier** имеет очень низкое качество, поэтому ее не стоит выбирать как приоритетную"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784ee547",
   "metadata": {},
   "source": [
    "Проверим на тестовой выборке лучшую модель - LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e6402b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best best_f1 = 0.6960991835500454\n"
     ]
    }
   ],
   "source": [
    "#best_model = grid_log.best_estimator_\n",
    "predict_test = model_tree.predict(features_test)\n",
    "f1 = f1_score(y_test, predict_test)\n",
    "\n",
    "print('Best best_f1 = {}'.format(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc1d76b",
   "metadata": {},
   "source": [
    "**Вывод:** Качество модели удовлетворяет ТЗ и равно F1 = 0.69"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555de1db-4ee7-4a15-a805-0d25b0c1256c",
   "metadata": {},
   "source": [
    "# Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26b140b-b890-4d82-9811-69f57dfd11e5",
   "metadata": {},
   "source": [
    "Мы провели исследование и обучили несколько разных моделей классификации, после этого выявили, что DecisionTreeClassifier имеет наиболее высокое качество, где F1 = 0.69. Также ходе обучения мы учли наличие дисбаланса классов, и перед обучением подготовили текст."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb73377",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
